{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ProgettoAIM.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "t68MYk9fukmZ"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "4dd6919f07ae4961b3597dc0295fb002": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_6c982054d88447ea8e6dc3954d3ca956",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_2a57723d15d3428e9cc059f039c19d80",
              "IPY_MODEL_dff743383af74946bcbbd67a9001e683"
            ]
          }
        },
        "6c982054d88447ea8e6dc3954d3ca956": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2a57723d15d3428e9cc059f039c19d80": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_468864af06ae4281b3483de33f33db85",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 128441847,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 128441847,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e0223876a623414fa13f1cb41edf56e3"
          }
        },
        "dff743383af74946bcbbd67a9001e683": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_dff1499245b1442891857e50823df296",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 122M/122M [31:11&lt;00:00, 68.6kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_335b5209a5fd460b8e635739e6eda091"
          }
        },
        "468864af06ae4281b3483de33f33db85": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e0223876a623414fa13f1cb41edf56e3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "dff1499245b1442891857e50823df296": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "335b5209a5fd460b8e635739e6eda091": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/antocommi/provagcp/blob/master/ProgettoAIM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3RHLRE_rdwjr",
        "outputId": "c5d5cc80-8078-43c0-e2a5-31210b6d31bb"
      },
      "source": [
        "# !pip3 install -q mmcv\n",
        "# !rm -rf mmaction2\n",
        "# !git clone https://github.com/open-mmlab/mmaction2.git\n",
        "# %cd mmaction2 \n",
        "# !pip install -r -q requirements/build.txt\n",
        "# !pip install -q -v -e .  # or \"python setup.py develop\"\n",
        "# %cd ..\n",
        "\n",
        "# # save state of colab\n",
        "# #from google.colab import drive\n",
        "# #drive.mount('/content/gdrive')\n",
        "# #!pip freeze --local > /content/gdrive/My\\ Drive/colab_installed.txt\n",
        "#ciao prova\n",
        "# import state of colab\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "!pip install -q --upgrade --force-reinstall `cat /content/gdrive/My\\ Drive/colab_installed.txt`"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 235kB 8.9MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 194kB 28.2MB/s \n",
            "\u001b[?25h  Building wheel for mmcv (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Cloning into 'mmaction2'...\n",
            "remote: Enumerating objects: 9261, done.\u001b[K\n",
            "remote: Total 9261 (delta 0), reused 0 (delta 0), pack-reused 9261\u001b[K\n",
            "Receiving objects: 100% (9261/9261), 35.28 MiB | 27.33 MiB/s, done.\n",
            "Resolving deltas: 100% (6572/6572), done.\n",
            "/content/mmaction2\n",
            "\u001b[31mERROR: Invalid requirement: 'requirements/build.txt'\n",
            "Hint: It looks like a path. It does exist. The argument you provided (requirements/build.txt) appears to be a requirements file. If that is the case, use the '-r' flag to install the packages specified within it.\u001b[0m\n",
            "Obtaining file:///content/mmaction2\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from mmaction2==0.11.0) (3.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from mmaction2==0.11.0) (1.19.5)\n",
            "Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.6/dist-packages (from mmaction2==0.11.0) (4.1.2.30)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (from mmaction2==0.11.0) (7.0.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->mmaction2==0.11.0) (2.8.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->mmaction2==0.11.0) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->mmaction2==0.11.0) (1.3.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->mmaction2==0.11.0) (2.4.7)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.1->matplotlib->mmaction2==0.11.0) (1.15.0)\n",
            "Installing collected packages: mmaction2\n",
            "  Running setup.py develop for mmaction2\n",
            "Successfully installed mmaction2\n",
            "/content\n",
            "Mounted at /content/gdrive\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 133kB 8.6MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61kB 6.9MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 737kB 12.0MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 102kB 11.0MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10.3MB 7.5MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2.8MB 50.3MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 51kB 8.6MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 378kB 55.4MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 37.2MB 71kB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8.8MB 53.2MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 92kB 13.0MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 286kB 55.6MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3.7MB 51.4MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19.3MB 1.3MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 92kB 13.8MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 153kB 54.6MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 409kB 47.6MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.0MB 48.3MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 143kB 57.0MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 92kB 14.1MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17.7MB 218kB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 51kB 7.6MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 286kB 60.2MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 92kB 12.1MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 81kB 10.6MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11.7MB 43.4MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 952kB 42.2MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2.0MB 14.6MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 798kB 45.9MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40kB 6.6MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5.2MB 46.0MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14.1MB 207kB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 81kB 12.0MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 512kB 49.6MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7.8MB 46.5MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3.1MB 48.0MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 296kB 54.7MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 552kB 49.2MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 71kB 10.3MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163kB 56.5MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 153kB 53.3MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 184kB 59.4MB/s \n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement en-core-web-sm==2.2.5 (from versions: none)\u001b[0m\n",
            "\u001b[31mERROR: No matching distribution found for en-core-web-sm==2.2.5\u001b[0m\n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mecebytbcLrw"
      },
      "source": [
        "SEED = 9126\n",
        "\n",
        "import os, cv2, json, time, math, sys, pickle\n",
        "from datetime import datetime\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "np.random.seed(SEED)\n",
        "import seaborn as sn\n",
        "\n",
        "# Check MMAction2 installation\n",
        "import mmaction\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.utils import compute_class_weight\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Z3LYU1fmiXE"
      },
      "source": [
        "Importing from Kaggle\n",
        "===="
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DIzdgV3ecyxy",
        "outputId": "64a54dd4-05c6-43ab-d1ef-49fd4748f3e5"
      },
      "source": [
        "# Download and load in memory dataset from kaggle\n",
        "!mkdir ~/.kaggle #create the .kaggle folder in your root directory\n",
        "!echo '{\"username\":\"antocommii\",\"key\":\"87dcebd7c4cb4ba4539ed72f027fcbde\"}' > ~/.kaggle/kaggle.json #write kaggle API credentials to kaggle.json\n",
        "!chmod 600 ~/.kaggle/kaggle.json  # set permissions\n",
        "!pip install -q kaggle #install the kaggle library\n",
        "!kaggle datasets download --unzip --force antocommii/spacejam-action-recognition -p /content/kaggle/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory â€˜/root/.kaggleâ€™: File exists\n",
            "Downloading spacejam-action-recognition.zip to /content/kaggle\n",
            "100% 624M/626M [00:05<00:00, 163MB/s]\n",
            "100% 626M/626M [00:05<00:00, 124MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8kOOsPYPmlch"
      },
      "source": [
        "Scelgo nuova size e definisco la struttura del Custom Dataset\n",
        "===="
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M5x2vHInmhnV",
        "outputId": "24d77f15-eeed-4cec-a7c9-b9ac85171524"
      },
      "source": [
        "# Definisco nuove dimensioni dei frame dei video per velocizzare la rete\n",
        "scale_factor_h, scale_factor_w = 0.637, 0.875 # 0.32, 0.44 -> 56,56 || 0.637, 0.875 -> 112,112\n",
        "new_H = math.floor(176 * scale_factor_h) # 176\n",
        "new_W = math.floor(128 * scale_factor_w) # 128\n",
        "print(\"New Size: \",new_H,new_W)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "New Size:  112 112\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5e5I2kBycS9D"
      },
      "source": [
        "new_H = new_W = 224\n",
        "\n",
        "class CustomSet(torch.utils.data.Dataset):\n",
        "    def __init__(self, videos_dir, list_dataset):\n",
        "        \"\"\" Construct an indexed list of video paths and labels \"\"\"\n",
        "        \n",
        "        self.VIDEO_DIR = videos_dir\n",
        "        \n",
        "        self.labels_dict = {0 : \"block\", 1 : \"pass\", 2 : \"run\", 3: \"dribble\",4: \"shoot\",\n",
        "          5 : \"ball in hand\", 6 : \"defense\", 7: \"pick\" , 8 : \"no_action\" , \n",
        "          9: \"walk\" ,10: \"discard\"}\n",
        "\n",
        "        self.dataset = list_dataset\n",
        "\n",
        "    def __getitem__(self, index, is_for_testing=True):\n",
        "        \"\"\" Load video n in the list of image paths and return it along with its label.\n",
        "            In the case of multiclass the label will probably be a list of values\"\"\"\n",
        "        \n",
        "        name, label = self.dataset[index]\n",
        "        \n",
        "        fname = os.path.join(self.VIDEO_DIR, name+'.mp4')\n",
        "        transform = transforms.Compose([\n",
        "                                        transforms.Resize((new_H,new_W)),\n",
        "                                        transforms.ToTensor()])\n",
        "        video = []\n",
        "        print(\"frames sampling enabled\")\n",
        "        accept = True\n",
        "        vid = cv2.VideoCapture(fname)\n",
        "        while True:\n",
        "            # Capture frame-by-frame\n",
        "            ret, frame = vid.read()\n",
        "            if ret:\n",
        "                frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "                frame = transform(Image.fromarray(frame))\n",
        "                frame = frame.unsqueeze(0)\n",
        "                if accept:\n",
        "                  video.append(frame)\n",
        "                  accept=False\n",
        "                else:\n",
        "                  accept=True\n",
        "            else:\n",
        "              #print(\"------------Non trovato!---------------\")\n",
        "              break\n",
        "\n",
        "        video = torch.cat(video, axis=0)\n",
        "        video = video.permute([1,0,2,3])\n",
        "        return {'video':video, 'label':torch.LongTensor([label])}\n",
        "        \n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\" return the total number of video in this dataset \"\"\"\n",
        "        return len(self.dataset)\n",
        "\n",
        "    def get_list(self):\n",
        "      return self.dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "khmMq62-mtba"
      },
      "source": [
        "Creazione Train, Validation e Test set\n",
        "===="
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wyvNusIhhr47",
        "outputId": "73b92bea-65b5-4296-a55d-730a24aaedbd"
      },
      "source": [
        "# abbiamo 10 classi\n",
        "num_classes = 10\n",
        "\n",
        "# il dataset Ã¨ ciÃ² che si ottiene dal metodo precedente\n",
        "ROOT_DIR = \"/content/kaggle/\"\n",
        "VIDEO_DIR = \"/content/kaggle/examples/\"\n",
        "ANNOTATION_FILE = \"annotation_dict.json\"\n",
        "TEST_SET_FILE = \"testset_keys_1lug2020.txt\"\n",
        "\n",
        "# prendo il dataset da annotation file\n",
        "with open(os.path.join(ROOT_DIR, ANNOTATION_FILE)) as fp:\n",
        "  annotations = json.load(fp)\n",
        "            \n",
        "with open(os.path.join(ROOT_DIR, TEST_SET_FILE)) as fp:\n",
        "  keys_test = json.load(fp)\n",
        "\n",
        "# divido in train e test second quello che ho nel file\n",
        "annotationTrain = dict(filter(lambda x: x[0] not in keys_test, annotations.items()))\n",
        "annotationTest = dict(filter(lambda x: x[0] in keys_test, annotations.items()))\n",
        "test_set = list(annotationTest.items())\n",
        "\n",
        "# divido in train e validation\n",
        "train_set, valid_set = train_test_split(list(annotationTrain.items()), test_size=0.1)\n",
        "\n",
        "#########################################################################\n",
        "#########################################################################\n",
        "# SOLO PER TEST #########################################################\n",
        "#train_set = train_set[:2000]  ###########################################\n",
        "#valid_set = valid_set[:200]   ###########################################\n",
        "#test_set = test_set[:100]     ###########################################\n",
        "#########################################################################\n",
        "#########################################################################\n",
        "\n",
        "# trasformo in custom_dataset\n",
        "train_ds = CustomSet(VIDEO_DIR, train_set)\n",
        "valid_ds = CustomSet(VIDEO_DIR, valid_set)\n",
        "test_ds = CustomSet(VIDEO_DIR, test_set)\n",
        "\n",
        "# definisco le batch_size\n",
        "BATCH_TRAIN_SIZE, BATCH_TEST_SIZE = 64,64\n",
        "\n",
        "# creo i dataloader\n",
        "trainLoader = DataLoader(train_ds, batch_size=BATCH_TRAIN_SIZE, shuffle=True)\n",
        "validLoader = DataLoader(valid_ds, batch_size=BATCH_TEST_SIZE, shuffle=True)\n",
        "testLoader = DataLoader(test_ds, batch_size=BATCH_TEST_SIZE, shuffle=True)\n",
        "\n",
        "# controllo se hanno la stessa forma di lista di tuple\n",
        "print(len(trainLoader)*BATCH_TRAIN_SIZE, len(valid_set), len(test_set))\n",
        "print(train_set[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "23424 2596 11126\n",
            "('0026091', 9)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eyocvCWEmyf0"
      },
      "source": [
        "Build modello\n",
        "===="
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LkGzlOn9SWRL"
      },
      "source": [
        "Rete prima\n",
        "--- \n",
        "\n",
        "https://github.com/open-mmlab/mmaction/blob/master/MODEL_ZOO.md"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122,
          "referenced_widgets": [
            "4dd6919f07ae4961b3597dc0295fb002",
            "6c982054d88447ea8e6dc3954d3ca956",
            "2a57723d15d3428e9cc059f039c19d80",
            "dff743383af74946bcbbd67a9001e683",
            "468864af06ae4281b3483de33f33db85",
            "e0223876a623414fa13f1cb41edf56e3",
            "dff1499245b1442891857e50823df296",
            "335b5209a5fd460b8e635739e6eda091"
          ]
        },
        "id": "nJS-xKXnvNHp",
        "outputId": "ddf2f3f2-388e-4a74-fe23-679ad0329088"
      },
      "source": [
        "from mmaction.apis import inference_recognizer, init_recognizer\n",
        "path='/content/mmaction2/'\n",
        "# Choose to use a config and initialize the recognizer\n",
        "config = path+'configs/recognition/omnisource/slowonly_r50_8x8x1_256e_minikinetics/slowonly_r50_8x8x1_256e_minikinetics_insvideo_rgb.py'\n",
        "# Setup a checkpoint file to load\n",
        "\n",
        "checkpoint = 'https://download.openmmlab.com/mmaction/recognition/omnisource/slowonly_r50_8x8x1_256e_minikinetics_rgb/insvideo/slowonly_r50_8x8x1_256e_minikinetics_insvideo_rgb_20201030-e2890e8d.pth'\n",
        "# Initialize the recognizer\n",
        "model = init_recognizer(config, checkpoint, device='cuda:0',use_frames=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Use load_from_http loader\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.openmmlab.com/mmaction/recognition/omnisource/slowonly_r50_8x8x1_256e_minikinetics_rgb/insvideo/slowonly_r50_8x8x1_256e_minikinetics_insvideo_rgb_20201030-e2890e8d.pth\" to /root/.cache/torch/hub/checkpoints/slowonly_r50_8x8x1_256e_minikinetics_insvideo_rgb_20201030-e2890e8d.pth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4dd6919f07ae4961b3597dc0295fb002",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=128441847.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_dQZdBPq4SXf"
      },
      "source": [
        "model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ZHSVbxg4UiI"
      },
      "source": [
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "    \n",
        "n_inputs = model.cls_head.fc_cls.in_features\n",
        "model.cls_head.fc_cls = nn.Linear(n_inputs, 10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RVIiOuI_afG4"
      },
      "source": [
        "Rete seconda\r\n",
        "----\r\n",
        "\r\n",
        "https://github.com/r1ch88/SlowFastNetworks/blob/master/lib/slowfastnet.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QWcB_XNyadot"
      },
      "source": [
        "_all__ = ['resnet50', 'resnet101','resnet152', 'resnet200']\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "class Bottleneck(nn.Module):\r\n",
        "    expansion = 4\r\n",
        "\r\n",
        "    def __init__(self, inplanes, planes, stride=1, downsample=None, head_conv=1):\r\n",
        "        super(Bottleneck, self).__init__()\r\n",
        "        if head_conv == 1:\r\n",
        "            self.conv1 = nn.Conv3d(inplanes, planes, kernel_size=1, bias=False)\r\n",
        "            self.bn1 = nn.BatchNorm3d(planes)\r\n",
        "        elif head_conv == 3:\r\n",
        "            self.conv1 = nn.Conv3d(inplanes, planes, kernel_size=(3, 1, 1), bias=False, padding=(1, 0, 0))\r\n",
        "            self.bn1 = nn.BatchNorm3d(planes)\r\n",
        "        else:\r\n",
        "            raise ValueError(\"Unsupported head_conv!\")\r\n",
        "        self.conv2 = nn.Conv3d(\r\n",
        "            planes, planes, kernel_size=(1, 3, 3), stride=(1,stride,stride), padding=(0, 1, 1), bias=False)\r\n",
        "        self.bn2 = nn.BatchNorm3d(planes)\r\n",
        "        self.conv3 = nn.Conv3d(planes, planes * 4, kernel_size=1, bias=False)\r\n",
        "        self.bn3 = nn.BatchNorm3d(planes * 4)\r\n",
        "        self.relu = nn.ReLU(inplace=True)\r\n",
        "        self.downsample = downsample\r\n",
        "        self.stride = stride\r\n",
        "\r\n",
        "    def forward(self, x):\r\n",
        "        residual = x\r\n",
        "\r\n",
        "        out = self.conv1(x)\r\n",
        "        out = self.bn1(out)\r\n",
        "        out = self.relu(out)\r\n",
        "\r\n",
        "        out = self.conv2(out)\r\n",
        "        out = self.bn2(out)\r\n",
        "        out = self.relu(out)\r\n",
        "\r\n",
        "        out = self.conv3(out)\r\n",
        "        out = self.bn3(out)\r\n",
        "\r\n",
        "        if self.downsample is not None:\r\n",
        "            residual = self.downsample(x)\r\n",
        "        out += residual\r\n",
        "        out = self.relu(out)\r\n",
        "\r\n",
        "        return out\r\n",
        "\r\n",
        "\r\n",
        "class SlowFast(nn.Module):\r\n",
        "    def __init__(self, block=Bottleneck, layers=[3, 4, 6, 3], class_num=10, dropout=0.5 ):\r\n",
        "        super(SlowFast, self).__init__()\r\n",
        "\r\n",
        "        self.fast_inplanes = 8\r\n",
        "        self.fast_conv1 = nn.Conv3d(3, 8, kernel_size=(5, 7, 7), stride=(1, 2, 2), padding=(2, 3, 3), bias=False)\r\n",
        "        self.fast_bn1 = nn.BatchNorm3d(8)\r\n",
        "        self.fast_relu = nn.ReLU(inplace=True)\r\n",
        "        self.fast_maxpool = nn.MaxPool3d(kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1))\r\n",
        "        self.fast_res2 = self._make_layer_fast(block, 8, layers[0], head_conv=3)\r\n",
        "        self.fast_res3 = self._make_layer_fast(\r\n",
        "            block, 16, layers[1], stride=2, head_conv=3)\r\n",
        "        self.fast_res4 = self._make_layer_fast(\r\n",
        "            block, 32, layers[2], stride=2, head_conv=3)\r\n",
        "        self.fast_res5 = self._make_layer_fast(\r\n",
        "            block, 64, layers[3], stride=2, head_conv=3)\r\n",
        "        \r\n",
        "        self.lateral_p1 = nn.Conv3d(8, 8*2, kernel_size=(5, 1, 1), stride=(8, 1 ,1), bias=False, padding=(2, 0, 0))\r\n",
        "        self.lateral_res2 = nn.Conv3d(32,32*2, kernel_size=(5, 1, 1), stride=(8, 1 ,1), bias=False, padding=(2, 0, 0))\r\n",
        "        self.lateral_res3 = nn.Conv3d(64,64*2, kernel_size=(5, 1, 1), stride=(8, 1 ,1), bias=False, padding=(2, 0, 0))\r\n",
        "        self.lateral_res4 = nn.Conv3d(128,128*2, kernel_size=(5, 1, 1), stride=(8, 1 ,1), bias=False, padding=(2, 0, 0))\r\n",
        "\r\n",
        "        self.slow_inplanes = 64+64//8*2\r\n",
        "        self.slow_conv1 = nn.Conv3d(3, 64, kernel_size=(1, 7, 7), stride=(1, 2, 2), padding=(0, 3, 3), bias=False)\r\n",
        "        self.slow_bn1 = nn.BatchNorm3d(64)\r\n",
        "        self.slow_relu = nn.ReLU(inplace=True)\r\n",
        "        self.slow_maxpool = nn.MaxPool3d(kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1))\r\n",
        "        self.slow_res2 = self._make_layer_slow(block, 64, layers[0], head_conv=1)\r\n",
        "        self.slow_res3 = self._make_layer_slow(\r\n",
        "            block, 128, layers[1], stride=2, head_conv=1)\r\n",
        "        self.slow_res4 = self._make_layer_slow(\r\n",
        "            block, 256, layers[2], stride=2, head_conv=3)\r\n",
        "        self.slow_res5 = self._make_layer_slow(\r\n",
        "            block, 512, layers[3], stride=2, head_conv=3)\r\n",
        "        self.dp = nn.Dropout(dropout)\r\n",
        "        self.fc = nn.Linear(self.fast_inplanes+2048, class_num, bias=False)\r\n",
        "    def forward(self, input ):\r\n",
        "        fast, lateral = self.FastPath(input[:, :, ::2, :, :])\r\n",
        "        slow = self.SlowPath(input[:, :, ::16, :, :], lateral)\r\n",
        "        x = torch.cat([slow, fast], dim=1)\r\n",
        "        x = self.dp(x)\r\n",
        "        x = self.fc(x)\r\n",
        "        return x\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "    def SlowPath(self, input, lateral):\r\n",
        "        x = self.slow_conv1(input)\r\n",
        "        x = self.slow_bn1(x)\r\n",
        "        x = self.slow_relu(x)\r\n",
        "        x = self.slow_maxpool(x)\r\n",
        "        x = torch.cat([x, lateral[0]],dim=1)\r\n",
        "        x = self.slow_res2(x)\r\n",
        "        x = torch.cat([x, lateral[1]],dim=1)\r\n",
        "        x = self.slow_res3(x)\r\n",
        "        x = torch.cat([x, lateral[2]],dim=1)\r\n",
        "        x = self.slow_res4(x)\r\n",
        "        x = torch.cat([x, lateral[3]],dim=1)\r\n",
        "        x = self.slow_res5(x)\r\n",
        "        x = nn.AdaptiveAvgPool3d(1)(x)\r\n",
        "        x = x.view(-1, x.size(1))\r\n",
        "        return x\r\n",
        "\r\n",
        "    def FastPath(self, input):\r\n",
        "        lateral = []\r\n",
        "        x = self.fast_conv1(input)\r\n",
        "        x = self.fast_bn1(x)\r\n",
        "        x = self.fast_relu(x)\r\n",
        "        pool1 = self.fast_maxpool(x)\r\n",
        "        lateral_p = self.lateral_p1(pool1)\r\n",
        "        lateral.append(lateral_p)\r\n",
        "\r\n",
        "        res2 = self.fast_res2(pool1)\r\n",
        "        lateral_res2 = self.lateral_res2(res2)\r\n",
        "        lateral.append(lateral_res2)\r\n",
        "        \r\n",
        "        res3 = self.fast_res3(res2)\r\n",
        "        lateral_res3 = self.lateral_res3(res3)\r\n",
        "        lateral.append(lateral_res3)\r\n",
        "\r\n",
        "        res4 = self.fast_res4(res3)\r\n",
        "        lateral_res4 = self.lateral_res4(res4)\r\n",
        "        lateral.append(lateral_res4)\r\n",
        "\r\n",
        "        res5 = self.fast_res5(res4)\r\n",
        "        x = nn.AdaptiveAvgPool3d(1)(res5)\r\n",
        "        x = x.view(-1, x.size(1))\r\n",
        "\r\n",
        "        return x, lateral\r\n",
        "\r\n",
        "    def _make_layer_fast(self, block, planes, blocks, stride=1, head_conv=1):\r\n",
        "        downsample = None\r\n",
        "        if stride != 1 or self.fast_inplanes != planes * block.expansion:\r\n",
        "            downsample = nn.Sequential(\r\n",
        "                nn.Conv3d(\r\n",
        "                    self.fast_inplanes,\r\n",
        "                    planes * block.expansion,\r\n",
        "                    kernel_size=1,\r\n",
        "                    stride=(1,stride,stride),\r\n",
        "                    bias=False), nn.BatchNorm3d(planes * block.expansion))\r\n",
        "\r\n",
        "        layers = []\r\n",
        "        layers.append(block(self.fast_inplanes, planes, stride, downsample, head_conv=head_conv))\r\n",
        "        self.fast_inplanes = planes * block.expansion\r\n",
        "        for i in range(1, blocks):\r\n",
        "            layers.append(block(self.fast_inplanes, planes, head_conv=head_conv))\r\n",
        "        return nn.Sequential(*layers)\r\n",
        "\r\n",
        "    def _make_layer_slow(self, block, planes, blocks, stride=1, head_conv=1):\r\n",
        "        downsample = None\r\n",
        "        if stride != 1 or self.slow_inplanes != planes * block.expansion:\r\n",
        "            downsample = nn.Sequential(\r\n",
        "                nn.Conv3d(\r\n",
        "                    self.slow_inplanes,\r\n",
        "                    planes * block.expansion,\r\n",
        "                    kernel_size=1,\r\n",
        "                    stride=(1,stride,stride),\r\n",
        "                    bias=False), nn.BatchNorm3d(planes * block.expansion))\r\n",
        "\r\n",
        "        layers = []\r\n",
        "        layers.append(block(self.slow_inplanes, planes, stride, downsample, head_conv=head_conv))\r\n",
        "        self.slow_inplanes = planes * block.expansion\r\n",
        "        for i in range(1, blocks):\r\n",
        "            layers.append(block(self.slow_inplanes, planes, head_conv=head_conv))\r\n",
        "  \r\n",
        "        self.slow_inplanes = planes * block.expansion + planes * block.expansion//8*2\r\n",
        "        return nn.Sequential(*layers)\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "def resnet50(**kwargs):\r\n",
        "    \"\"\"Constructs a ResNet-50 model.\r\n",
        "    \"\"\"\r\n",
        "    model = SlowFast(Bottleneck, [3, 4, 6, 3], **kwargs)\r\n",
        "    return model\r\n",
        "\r\n",
        "\r\n",
        "def resnet101(**kwargs):\r\n",
        "    \"\"\"Constructs a ResNet-101 model.\r\n",
        "    \"\"\"\r\n",
        "    model = SlowFast(Bottleneck, [3, 4, 23, 3], **kwargs)\r\n",
        "    return model\r\n",
        "\r\n",
        "\r\n",
        "def resnet152(**kwargs):\r\n",
        "    \"\"\"Constructs a ResNet-101 model.\r\n",
        "    \"\"\"\r\n",
        "    model = SlowFast(Bottleneck, [3, 8, 36, 3], **kwargs)\r\n",
        "    return model\r\n",
        "\r\n",
        "\r\n",
        "def resnet200(**kwargs):\r\n",
        "    \"\"\"Constructs a ResNet-101 model.\r\n",
        "    \"\"\"\r\n",
        "    model = SlowFast(Bottleneck, [3, 24, 36, 3], **kwargs)\r\n",
        "    return model\r\n",
        "\r\n",
        "model = SlowFast(class_num=400)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gT-DfaFLbXhm"
      },
      "source": [
        "model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S06QUvFndBbd"
      },
      "source": [
        "n_inputs = model.fc.in_features\r\n",
        "model.fc = nn.Linear(n_inputs, 10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eREQ3WCrsi1Z"
      },
      "source": [
        "model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uKpTDWtyorUz"
      },
      "source": [
        "Training modello\n",
        "===="
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VfNX6tByotkB"
      },
      "source": [
        "def train_one_epoch(model, optimizer, trainloader, epoch, num_epochs):\n",
        "  model.train()\n",
        "  running_loss = 0.0\n",
        "  train_correct = 0\n",
        "  \n",
        "  for batch_i,item in enumerate(trainloader):\n",
        "    video, target = item['video'], item['label']\n",
        "    target = torch.reshape(target, (-1,))\n",
        "    video, target = video.cuda(), target.cuda()\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model(video)  # senza SlowFast ResNet50 Ã¨ outputs=model(video)\n",
        "\n",
        "    loss = criterion(outputs, target)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "    correct_lbls = (predicted == target).sum().item()\n",
        "    train_correct = train_correct + correct_lbls\n",
        "    running_loss = running_loss + loss.item()\n",
        "\n",
        "    # Print log\n",
        "    sys.stdout.write(\n",
        "      \"\\r[Epoch %d/%d] [Batch %d/%d] [Loss: %f (%f), Acc: %.2f%% (%.2f%%)] [lr: %.7f%%]\"\n",
        "      % (\n",
        "        epoch+1,\n",
        "        num_epochs,\n",
        "        batch_i,\n",
        "        len(trainloader),\n",
        "        loss.item(),\n",
        "        running_loss/(1+batch_i),\n",
        "        correct_lbls/float(BATCH_TRAIN_SIZE),\n",
        "        train_correct/float(BATCH_TRAIN_SIZE*(1+batch_i)),\n",
        "        optimizer.param_groups[0]['lr']\n",
        "      )\n",
        "    )\n",
        "\n",
        "\n",
        "  return [running_loss, train_correct]\n",
        "\n",
        "\n",
        "def evaluate(model, validloader, isTestingPhase):\n",
        "  model.eval()\n",
        "  running_loss = 0.0\n",
        "  valid_correct = 0\n",
        "  if isTestingPhase:\n",
        "    predicts, labels = [],[]\n",
        "  \n",
        "  with torch.no_grad():\n",
        "    for item in validloader:\n",
        "      video, target = item['video'], item['label']\n",
        "      target = torch.reshape(target, (-1,))\n",
        "      \n",
        "      video, target = video.cuda(), target.cuda()\n",
        "      # INFERENCE CALCULATING\n",
        "      outputs = model(video) # senza SlowFast ResNet50 Ã¨ outputs=model(video)\n",
        "      val_loss = criterion(outputs, target)\n",
        "      # MONITORING ACCURACY AND LOSS      \n",
        "      _, predicted = torch.max(outputs.data, 1)\n",
        "      valid_correct = valid_correct + (predicted == target).sum().item()\n",
        "      running_loss += val_loss.item()\n",
        "\n",
        "      if isTestingPhase:\n",
        "        predicts.append(predicted.item())\n",
        "        labels.append(target.item())\n",
        "\n",
        "  if isTestingPhase:\n",
        "    return [(predicts, labels), running_loss, valid_correct]\n",
        "  \n",
        "  else:\n",
        "    return [None, running_loss, valid_correct]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Air4ikJfsXCT",
        "outputId": "331b19ae-34ad-4fa6-8147-e0cafd696c80"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9TAB4VDr18VR"
      },
      "source": [
        "# # DOPO AVER ESEGUITO QUESTA CELLA RIAVVIARE IL RUNTIME!\r\n",
        "!git clone \"https://github.com/facebookresearch/VMZ\"\r\n",
        "!pip install -e VMZ/pt/\r\n",
        "# # DOPO AVER ESEGUITO QUESTA CELLA RIAVVIARE IL RUNTIME!"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uR43VYFU2CGO"
      },
      "source": [
        "from vmz.models import ir_csn_152\r\n",
        "model = ir_csn_152(pretraining=\"ig_ft_kinetics_32frms\")\r\n",
        "\r\n",
        "for param in model.parameters():\r\n",
        "    param.requires_grad = False\r\n",
        "\r\n",
        "n_inputs = model.fc.in_features\r\n",
        "model.fc = nn.Linear(n_inputs, 10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gHy3wyv9owPu"
      },
      "source": [
        "torch.cuda.empty_cache()\n",
        "\n",
        "model.cuda()\n",
        "\n",
        "lr = 1e-3\n",
        "print(\"parametri training (\",new_H,new_W,\")\",\"lr:\",lr,\"batch_size:\",BATCH_TRAIN_SIZE)\n",
        "# costruisco i pesi per la loss per il dataset sbilanciato\n",
        "y_train = [v for k,v in train_set]\n",
        "weights = torch.FloatTensor(compute_class_weight('balanced', np.unique(y_train), y_train )).cuda()\n",
        "\n",
        "# costruisco optimizer, criterio di loss, parametri di training\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(),lr=lr)\n",
        "\n",
        "EPOCHS=50\n",
        "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1) # classico\n",
        "# lr_scheduler = ReduceLROnPlateau(optimizer, mode='min', patience=5, factor=0.1, min_lr=1e-6) # varia lr su plateau\n",
        "\n",
        "tr_loss, val_loss = [], []\n",
        "tr_accs, val_accs = [], []\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "  # train for one epoch\n",
        "  start_time = time.time()\n",
        "  train_loss, train_correct = train_one_epoch(model, optimizer, trainLoader, epoch, EPOCHS)\n",
        "  end_time = time.time() - start_time\n",
        "\n",
        "  # validate on validation set\n",
        "  _, valid_loss, valid_correct = evaluate(model, validLoader, isTestingPhase=False)\n",
        "\n",
        "  # lr_scheduler.step( valid_loss/float(len(validLoader)) )\n",
        "  lr_scheduler.step()\n",
        "  print(\n",
        "      f' [Val_loss = {valid_loss/float(len(validLoader)):0.7f},'\n",
        "      f' Val_acc = {valid_correct/float(len(validLoader)*BATCH_TEST_SIZE):0.7f}]',\n",
        "      f'in {end_time:.2f} sec'\n",
        "  )\n",
        "\n",
        "  tr_loss.append(train_loss/float(len(trainLoader)))\n",
        "  val_loss.append(valid_loss/float(len(validLoader)))\n",
        "  tr_accs.append(float(train_correct)/float(len(trainLoader)*BATCH_TRAIN_SIZE))\n",
        "  val_accs.append(float(valid_correct)/float(len(validLoader)*BATCH_TEST_SIZE))\n",
        "\n",
        "  checkpoint = {\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'loss': criterion,\n",
        "            'scheduler':lr_scheduler.state_dict()\n",
        "  }\n",
        "\n",
        "  path=\"drive/MyDrive/\"\n",
        "  torch.save(checkpoint, path+'model_train_e'+str(epoch)+'.pth')\n",
        "\n",
        "plt.plot(tr_loss, label='Training loss', c='r')\n",
        "plt.plot(val_loss, label='Validation loss', c='b')\n",
        "plt.legend(frameon=False)\n",
        "plt.show()\n",
        "\n",
        "plt.plot(tr_accs, label='Training accuracy', c='r')\n",
        "plt.plot(val_accs, label='Validation accuracy', c='b')\n",
        "plt.legend(frameon=False)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z34AP_KojVHq"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WBhQiqiPixc_"
      },
      "source": [
        "output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t68MYk9fukmZ"
      },
      "source": [
        "Testing\n",
        "===="
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PDmhI9Qzumpw"
      },
      "source": [
        "outputTargetTuple, test_loss, test_correct = evaluate(model, testLoader, isTestingPhase=True)\n",
        "print(f'Accuracy = {(test_correct/float(len(testLoader)*BATCH_TEST_SIZE))*100}%')\n",
        "print(classification_report(y_true=outputTargetTuple[0], y_pred=outputTargetTuple[1], zero_division=0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HmVb0kXs1ywi"
      },
      "source": [
        "confusion_matrix( y_true=outputTargetTuple[0], y_pred=outputTargetTuple[1], labels=np.arange(0,10) )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T3qOb3J1uphG"
      },
      "source": [
        "print(outputTargetTuple[0])\n",
        "print(outputTargetTuple[1])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}